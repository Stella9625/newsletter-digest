<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>AI/äº§å“/æŠ€æœ¯æ—¥æŠ¥ - æ–‡ç« å…¨æ–‡</title>
    <link>https://stella9625.github.io/newsletter-digest</link>
    <description>æ¯ç¯‡æ–‡ç« çš„ä¸­æ–‡æ‘˜è¦å’Œå…¨æ–‡ç¿»è¯‘</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>zh-CN</language>
    <lastBuildDate>Fri, 20 Feb 2026 22:47:31 +0000</lastBuildDate>
    <item>
      <title>[ç¿»è¯‘] TLDR AI: Gemini 3.1 Proå‘å¸ƒã€ä¸‡èƒ½ä¼˜åŒ–APIä¸æ™ºèƒ½ä½“æ²™ç›’æŠ€æœ¯</title>
      <link>https://tldr.tech/ai/2026-02-20</link>
      <description>&lt;p&gt;&lt;strong&gt;æ ‡ç­¾:&lt;/strong&gt; #Gemini #AIæ™ºèƒ½ä½“ #ä¼˜åŒ– #æ²™ç®±&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;æ‘˜è¦:&lt;/strong&gt; æœ¬æœŸå†…å®¹æ¶µç›–Google Gemini 3.1 Proå¤§æ¨¡å‹é‡å¤§å‡çº§ï¼ˆARC-AGI-2æ€§èƒ½ç¿»å€ï¼‰ã€Cursoræœ¬åœ°æ™ºèƒ½ä½“æ²™ç›’å®‰å…¨æ–¹æ¡ˆï¼Œä»¥åŠoptimize_anythingé€šç”¨æ–‡æœ¬ä¼˜åŒ–APIç­‰å‰æ²¿è¿›å±•ï¼Œå±•ç°äº†å¤§æ¨¡å‹æ¨ç†èƒ½åŠ›çªç ´ä¸å·¥ç¨‹å®è·µåˆ›æ–°çš„åŒé‡æå‡ã€‚&lt;/p&gt;
&lt;p style="color:#888;font-size:13px;"&gt;åŸæ ‡é¢˜: Gemini 3.1 Pro ğŸ§ , optimize anything ğŸ“ˆ, agent sandboxing ğŸ”&lt;/p&gt;
&lt;hr/&gt;
&lt;h3 style="margin:24px 0 12px;"&gt;TLDR AI 2026-02-20&lt;/h3&gt;

&lt;h3 style="margin:24px 0 12px;"&gt;Gemini 3.1 Pro ğŸ§ , optimize anything ğŸ“ˆ, agent sandboxing ğŸ”&lt;/h3&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;
&lt;h4&gt;Google test NotebookLM integration for Opal workflows (1 minute read)&lt;/h4&gt;
&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;
&lt;h4&gt;Google æµ‹è¯• NotebookLM ä¸ Opal å·¥ä½œæµçš„é›†æˆï¼ˆ1 åˆ†é’Ÿé˜…è¯»ï¼‰&lt;/h4&gt;
&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;
Google tests &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;NotebookLM&lt;/strong&gt; integration within &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;Opal&lt;/strong&gt; workflows, enhancing data extraction and automation. This integration aims to streamline processes and improve workflow efficiency for users.
&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;
Google æ­£åœ¨æµ‹è¯• &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;NotebookLM&lt;/strong&gt; ä¸ &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;Opal&lt;/strong&gt; å·¥ä½œæµçš„é›†æˆï¼Œä»¥å¢å¼ºæ•°æ®æå–å’Œè‡ªåŠ¨åŒ–èƒ½åŠ›ã€‚è¯¥é›†æˆæ—¨åœ¨ç®€åŒ–æµç¨‹å¹¶æé«˜ç”¨æˆ·çš„å·¥ä½œæµæ•ˆç‡ã€‚
&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;
&lt;h4&gt;Gemini 3.1 Pro (5 minute read)&lt;/h4&gt;
&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;
&lt;h4&gt;Gemini 3.1 Proï¼ˆ5 åˆ†é’Ÿé˜…è¯»ï¼‰&lt;/h4&gt;
&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;
&lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;Google&lt;/strong&gt; released &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;Gemini 3.1 Pro&lt;/strong&gt; as the upgraded core model behind recent Gemini 3 "&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;Deep Think&lt;/strong&gt;" improvements, and began rolling it out to the Gemini API/AI Studio, Vertex AI, Android Studio, the Gemini app, and NotebookLM. The post highlighted a verified 77.1% score on &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;ARC-AGI-2&lt;/strong&gt;, more than doubling Gemini 3 Pro's result.
&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;
&lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;Google&lt;/strong&gt; å‘å¸ƒäº† &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;Gemini 3.1 Pro&lt;/strong&gt;ï¼Œä½œä¸ºè¿‘æœŸ Gemini 3 "&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;Deep Think&lt;/strong&gt;"ï¼ˆæ·±åº¦æ€è€ƒï¼‰åŠŸèƒ½æ”¹è¿›çš„å‡çº§æ ¸å¿ƒæ¨¡å‹ï¼Œå¹¶å¼€å§‹å°†å…¶æ¨å‡ºè‡³ Gemini API/AI Studioã€Vertex AIã€Android Studioã€Gemini åº”ç”¨å’Œ NotebookLMã€‚è¯¥å…¬å‘Šå¼ºè°ƒäº†å…¶åœ¨ &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;ARC-AGI-2&lt;/strong&gt; åŸºå‡†æµ‹è¯•ä¸ŠéªŒè¯è¾¾åˆ°çš„ 77.1% å¾—åˆ†ï¼Œæ˜¯ Gemini 3 Pro ç»“æœçš„ä¸¤å€å¤šã€‚
&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;
&lt;h4&gt;Implementing a secure sandbox for local agents (7 minute read)&lt;/h4&gt;
&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;
&lt;h4&gt;ä¸ºæœ¬åœ°æ™ºèƒ½ä½“å®ç°å®‰å…¨æ²™ç®±ï¼ˆ7 åˆ†é’Ÿé˜…è¯»ï¼‰&lt;/h4&gt;
&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;
&lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;Cursor&lt;/strong&gt; described an "&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;agent sandboxing&lt;/strong&gt;" system that let local coding agents run freely inside a constrained environment and only asked for approval when leaving the sandbox (often for internet access).
&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;
&lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;Cursor&lt;/strong&gt; æè¿°äº†ä¸€ç§"&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;æ™ºèƒ½ä½“æ²™ç®±&lt;/strong&gt;ï¼ˆagent sandboxingï¼‰"ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿå…è®¸æœ¬åœ°ç¼–ç¨‹æ™ºèƒ½ä½“åœ¨å—çº¦æŸçš„ç¯å¢ƒä¸­è‡ªç”±è¿è¡Œï¼Œä»…åœ¨ç¦»å¼€æ²™ç®±ï¼ˆé€šå¸¸æ˜¯ä¸ºäº†è®¿é—®äº’è”ç½‘ï¼‰æ—¶æ‰éœ€è¦è¯·æ±‚æ‰¹å‡†ã€‚
&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;
&lt;h4&gt;ARC-AGI-3 UPDATE (5 minute read)&lt;/h4&gt;
&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;
&lt;h4&gt;ARC-AGI-3 æ›´æ–°ï¼ˆ5 åˆ†é’Ÿé˜…è¯»ï¼‰&lt;/h4&gt;
&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;
&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;ARC-AGI-3&lt;/strong&gt; is an Interactive Reasoning Benchmark designed to measure an AI Agent's ability to generalize in novel, unseen environments. &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;Opus 4.6&lt;/strong&gt; demonstrates better reasoning and use of memory than &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;Gemini 3.1 Pro&lt;/strong&gt; and solves more levels. Current models may be able to solve ARC-AGI-3 given access to a harness with a simple memory. Memory scaffolds are likely enough for pseudo-continual learning to push us to some self-improvement or research-agent threshold within the next 2 years.
&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;
&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;ARC-AGI-3&lt;/strong&gt; æ˜¯ä¸€ä¸ªäº¤äº’å¼æ¨ç†åŸºå‡†æµ‹è¯•ï¼ˆInteractive Reasoning Benchmarkï¼‰ï¼Œæ—¨åœ¨è¡¡é‡ AI æ™ºèƒ½ä½“åœ¨å…¨æ–°çš„ã€æœªè§è¿‡çš„ç¯å¢ƒä¸­è¿›è¡Œæ³›åŒ–çš„èƒ½åŠ›ã€‚&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;Opus 4.6&lt;/strong&gt; å±•ç°å‡ºæ¯” &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;Gemini 3.1 Pro&lt;/strong&gt; æ›´å¼ºçš„æ¨ç†å’Œè®°å¿†ä½¿ç”¨èƒ½åŠ›ï¼Œå¹¶è§£å†³äº†æ›´å¤šå…³å¡ã€‚å¦‚æœå½“å‰æ¨¡å‹èƒ½å¤Ÿä½¿ç”¨å¸¦æœ‰ç®€å•è®°å¿†æœºåˆ¶çš„ harnessï¼ˆæµ‹è¯•æ¡†æ¶ï¼‰ï¼Œå®ƒä»¬å¯èƒ½èƒ½å¤Ÿè§£å†³ ARC-AGI-3ã€‚è®°å¿†æ”¯æ¶ï¼ˆmemory scaffoldsï¼‰å¾ˆå¯èƒ½è¶³ä»¥æ”¯æŒä¼ªæŒç»­å­¦ä¹ ï¼ˆpseudo-continual learningï¼‰ï¼Œåœ¨æœªæ¥ 2 å¹´å†…æ¨åŠ¨æˆ‘ä»¬è¾¾åˆ°æŸç§è‡ªæˆ‘æ”¹è¿›æˆ–ç ”ç©¶å‹æ™ºèƒ½ä½“çš„é˜ˆå€¼ã€‚
&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;
&lt;h4&gt;AI #156 Part 1: They Do Mean The Effect On Jobs (58 minute read)&lt;/h4&gt;
&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;
&lt;h4&gt;AI #156 ç¬¬ä¸€éƒ¨åˆ†ï¼šä»–ä»¬ç¡®å®æŒ‡çš„æ˜¯å¯¹å°±ä¸šçš„å½±å“ï¼ˆ58 åˆ†é’Ÿé˜…è¯»ï¼‰&lt;/h4&gt;
&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;
This post contains a roundup of what happened in AI this week. It focuses on projections of jobs and economic impacts and also timelines to the world being transformed. It also covers recent podcasts with &lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;Dario Amodei&lt;/strong&gt; and &lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;Elon Musk&lt;/strong&gt;. A linked table of contents with a short description for each section is available.
&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;
æœ¬æ–‡æ±‡æ€»äº†æœ¬å‘¨ AI é¢†åŸŸå‘ç”Ÿçš„äº‹ä»¶ã€‚å®ƒé‡ç‚¹å…³æ³¨å°±ä¸šå’Œç»æµå½±å“çš„é¢„æµ‹ï¼Œä»¥åŠä¸–ç•Œè¢«æ”¹å˜çš„æ—¶é—´çº¿ã€‚æ–‡ç« è¿˜æ¶µç›–äº†ä¸ &lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;Dario Amodei&lt;/strong&gt; å’Œ &lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;Elon Musk&lt;/strong&gt; çš„è¿‘æœŸæ’­å®¢å†…å®¹ã€‚æ–‡ä¸­æä¾›äº†å¸¦é“¾æ¥çš„ç›®å½•ï¼Œæ¯ä¸ªéƒ¨åˆ†éƒ½æœ‰ç®€çŸ­æè¿°ã€‚
&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;
&lt;h4&gt;ğŸ‘¨â€ğŸ’» Engineering &amp; Research&lt;/h4&gt;
&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;
&lt;h4&gt;ğŸ‘¨â€ğŸ’» å·¥ç¨‹ä¸ç ”ç©¶&lt;/h4&gt;
&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;
&lt;h4&gt;Crusoe: deploy fine-tuned models with zero infrastructure headaches (Sponsor)&lt;/h4&gt;
&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;
&lt;h4&gt;Crusoeï¼šé›¶åŸºç¡€è®¾æ–½çƒ¦æ¼éƒ¨ç½²å¾®è°ƒæ¨¡å‹ï¼ˆèµåŠ©å•†ï¼‰&lt;/h4&gt;
&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;
Looking to deploy AI that you actually own?
&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;
å¸Œæœ›éƒ¨ç½²ä½ çœŸæ­£æ‹¥æœ‰çš„ AIï¼Ÿ
&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;
&lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;Crusoe&lt;/strong&gt; unlocks breakthrough speed and throughput without the infra overhead. Run SOTA fine-tuned models: &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;DeepSeek&lt;/strong&gt;, &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;gpt-oss&lt;/strong&gt;, &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;Kimi&lt;/strong&gt;, or bring your own. Power production apps with high reliability. Focus on innovation and leave the clusters to Crusoe's expert team.
&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;
&lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;Crusoe&lt;/strong&gt; æ— éœ€åŸºç¡€è®¾æ–½å¼€é”€å³å¯è§£é”çªç ´æ€§çš„é€Ÿåº¦å’Œååé‡ã€‚è¿è¡Œæœ€å…ˆè¿›çš„å¾®è°ƒæ¨¡å‹ï¼š&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;DeepSeek&lt;/strong&gt;ã€&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;gpt-oss&lt;/strong&gt;ã€&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;Kimi&lt;/strong&gt;ï¼Œæˆ–æºå¸¦ä½ è‡ªå·±çš„æ¨¡å‹ã€‚ä»¥é«˜å¯é æ€§ä¸ºç”Ÿäº§çº§åº”ç”¨æä¾›åŠ¨åŠ›ã€‚ä¸“æ³¨äºåˆ›æ–°ï¼Œå°†é›†ç¾¤ç®¡ç†äº¤ç»™ Crusoe çš„ä¸“ä¸šå›¢é˜Ÿã€‚
&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;
&lt;h4&gt;Multi-Agent Cooperation (9 minute read)&lt;/h4&gt;
&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;
&lt;h4&gt;å¤šæ™ºèƒ½ä½“åä½œï¼ˆ9 åˆ†é’Ÿé˜…è¯»ï¼‰&lt;/h4&gt;
&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;
Building on &lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;Google&lt;/strong&gt;'s &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;Transformer&lt;/strong&gt; architecture, the authors proposed training sequence-model agents against many different opponents so they learned to adapt within each game without hardcoded assumptions about how others learn.
&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;
åŸºäº &lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;Google&lt;/strong&gt; çš„ &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;Transformer&lt;/strong&gt; æ¶æ„ï¼Œä½œè€…ä»¬æå‡ºè®­ç»ƒåºåˆ—æ¨¡å‹æ™ºèƒ½ä½“å¯¹æŠ—è®¸å¤šä¸åŒçš„å¯¹æ‰‹ï¼Œä½¿å®ƒä»¬å­¦ä¼šåœ¨æ¯ä¸ªæ¸¸æˆä¸­è‡ªé€‚åº”ï¼Œè€Œæ— éœ€å…³äºå…¶ä»–æ™ºèƒ½ä½“å¦‚ä½•å­¦ä¹ çš„ç¡¬ç¼–ç å‡è®¾ã€‚
&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;
&lt;h4&gt;optimize_anything: A Universal API for Optimizing any Text Parameter (132 minute read)&lt;/h4&gt;
&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;
&lt;h4&gt;optimize_anythingï¼šä¼˜åŒ–ä»»ä½•æ–‡æœ¬å‚æ•°çš„é€šç”¨ APIï¼ˆ132 åˆ†é’Ÿé˜…è¯»ï¼‰&lt;/h4&gt;
&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;
&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;optimize_anything&lt;/strong&gt; is a declarative API that optimizes any artifact representable as text. Users declare what to optimize and how to measure it, and the system handles the search. It consistently matches or outperforms domain-specific tools. A surprisingly wide range of problems can be formulated as optimizing a text artifact. If it can be serialized to a string and its quality measured, a large language model can reason about it and propose improvements.
&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;
&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;optimize_anything&lt;/strong&gt; æ˜¯ä¸€ä¸ªå£°æ˜å¼ APIï¼ˆdeclarative APIï¼‰ï¼Œå¯ä»¥ä¼˜åŒ–ä»»ä½•å¯è¡¨ç¤ºä¸ºæ–‡æœ¬çš„å·¥ä»¶ï¼ˆartifactï¼‰ã€‚ç”¨æˆ·å£°æ˜è¦ä¼˜åŒ–çš„å†…å®¹ä»¥åŠå¦‚ä½•è¡¡é‡å®ƒï¼Œç³»ç»Ÿåˆ™è´Ÿè´£å¤„ç†æœç´¢è¿‡ç¨‹ã€‚å®ƒå§‹ç»ˆèƒ½å¤Ÿä¸ç‰¹å®šé¢†åŸŸå·¥å…·ç›¸åŒ¹é…æˆ–è¶…è¶Šå…¶æ€§èƒ½ã€‚ä»¤äººæƒŠè®¶çš„æ˜¯ï¼ŒèŒƒå›´æå¹¿çš„é—®é¢˜éƒ½å¯ä»¥è¢«å½¢å¼åŒ–ä¸ºä¼˜åŒ–æ–‡æœ¬å·¥ä»¶ã€‚å¦‚æœæŸç‰©å¯ä»¥è¢«åºåˆ—åŒ–ä¸ºå­—ç¬¦ä¸²ä¸”å…¶è´¨é‡å¯ä»¥è¢«è¡¡é‡ï¼Œé‚£ä¹ˆå¤§è¯­è¨€æ¨¡å‹ï¼ˆlarge language model, LLMï¼‰å°±èƒ½å¯¹å…¶è¿›è¡Œæ¨ç†å¹¶æå‡ºæ”¹è¿›å»ºè®®ã€‚
&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;
&lt;h4&gt;Repeating Prompts (1 minute read)&lt;/h4&gt;
&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;
&lt;h4&gt;é‡å¤æç¤ºï¼ˆ1 åˆ†é’Ÿé˜…è¯»ï¼‰&lt;/h4&gt;
&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;
When not using reasoning, repeating the input prompt improves performance for popular models without increasing the number of generated tokens or latency. It is interesting that tricks like this are still possible despite the amount of work being put into improving large language models. The discovery proves how much room for improvement there still is for current models.
&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;
åœ¨ä¸ä½¿ç”¨æ¨ç†ï¼ˆreasoningï¼‰åŠŸèƒ½æ—¶ï¼Œé‡å¤è¾“å…¥æç¤ºå¯ä»¥æé«˜æµè¡Œæ¨¡å‹çš„æ€§èƒ½ï¼Œè€Œä¸ä¼šå¢åŠ ç”Ÿæˆ token çš„æ•°é‡æˆ–å»¶è¿Ÿã€‚å°½ç®¡äººä»¬åœ¨æ”¹è¿›å¤§è¯­è¨€æ¨¡å‹æ–¹é¢æŠ•å…¥äº†å¤§é‡å·¥ä½œï¼Œä½†åƒè¿™æ ·çš„æŠ€å·§ä»ç„¶å¯è¡Œï¼Œè¿™å¾ˆæœ‰è¶£ã€‚è¿™ä¸€å‘ç°è¯æ˜äº†å½“å‰æ¨¡å‹ä»æœ‰å·¨å¤§çš„æ”¹è¿›ç©ºé—´ã€‚
&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;
&lt;h4&gt;9 Observations from Building with AI Agents (2 minute read)&lt;/h4&gt;
&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;
&lt;h4&gt;æ„å»º AI æ™ºèƒ½ä½“çš„ 9 ä¸ªè§‚å¯Ÿï¼ˆ2 åˆ†é’Ÿé˜…è¯»ï¼‰&lt;/h4&gt;
&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;
Prototype with the best and polish small gems. Use teams of agents as micromanagers, and experiment with different tools and workflows. Document everything to create improvement loops that improve success rates without manual intervention. Skills are easier to debug than code.
&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;
ç”¨æœ€å¥½çš„æ¨¡å‹è¿›è¡ŒåŸå‹è®¾è®¡ï¼Œå¹¶æ‰“ç£¨å°çš„ç²¾åéƒ¨åˆ†ã€‚ä½¿ç”¨æ™ºèƒ½ä½“å›¢é˜Ÿä½œä¸ºå¾®è§‚ç®¡ç†è€…ï¼ˆmicromanagersï¼‰ï¼Œå¹¶å°è¯•ä¸åŒçš„å·¥å…·å’Œå·¥ä½œæµã€‚è®°å½•æ‰€æœ‰å†…å®¹ä»¥åˆ›å»ºæ”¹è¿›å¾ªç¯ï¼ˆimprovement loopsï¼‰ï¼Œä»è€Œåœ¨æ²¡æœ‰äººå·¥å¹²é¢„çš„æƒ…å†µä¸‹æé«˜æˆåŠŸç‡ã€‚æŠ€èƒ½ï¼ˆskillsï¼‰æ¯”ä»£ç æ›´å®¹æ˜“è°ƒè¯•ã€‚
&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;
&lt;h4&gt;How will OpenAI compete? (25 minute read)&lt;/h4&gt;
&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;
&lt;h4&gt;OpenAI å°†å¦‚ä½•ç«äº‰ï¼Ÿï¼ˆ25 åˆ†é’Ÿé˜…è¯»ï¼‰&lt;/h4&gt;
&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;
&lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;OpenAI&lt;/strong&gt; has a big user base, but it has limited engagement and stickiness and no network effect. The company doesn't have any unique technology. The incumbents have already matched the technology and are leveraging their product and distribution. This post takes a look at OpenAI's strategy and how the company can compete in today's landscape.
&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;
&lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;OpenAI&lt;/strong&gt; æ‹¥æœ‰åºå¤§çš„ç”¨æˆ·åŸºç¡€ï¼Œä½†å…¶ç”¨æˆ·å‚ä¸åº¦å’Œç²˜æ€§æœ‰é™ï¼Œä¸”æ²¡æœ‰ç½‘ç»œæ•ˆåº”ã€‚è¯¥å…¬å¸æ²¡æœ‰ä»»ä½•ç‹¬ç‰¹çš„æŠ€æœ¯ã€‚ç°æœ‰ç«äº‰å¯¹æ‰‹ï¼ˆincumbentsï¼‰å·²ç»èµ¶ä¸Šäº†æŠ€æœ¯æ°´å¹³ï¼Œå¹¶æ­£åœ¨åˆ©ç”¨å…¶äº§å“å’Œåˆ†é”€æ¸ é“ã€‚æœ¬æ–‡æ¢è®¨äº† OpenAI çš„æˆ˜ç•¥ä»¥åŠè¯¥å…¬å¸å¦‚ä½•åœ¨å½“ä»Šçš„ç«äº‰æ ¼å±€ä¸­ä¿æŒç«äº‰åŠ›ã€‚
&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;
&lt;h3&gt;Get the most interesting AI stories and breakthroughs delivered in a free daily email.&lt;/h3&gt;
&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;
&lt;h3&gt;é€šè¿‡å…è´¹æ¯æ—¥é‚®ä»¶è·å–æœ€æœ‰è¶£çš„ AI æ•…äº‹å’Œçªç ´æ€§è¿›å±•ã€‚&lt;/h3&gt;
&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;
Join 920,000 readers for
&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;
åŠ å…¥ 920,000 åè¯»è€…
&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;ğŸ”— &lt;a href="https://tldr.tech/ai/2026-02-20"&gt;é˜…è¯»åŸæ–‡&lt;/a&gt;&lt;/p&gt;</description>
      <guid isPermaLink="false">https://tldr.tech/ai/2026-02-20</guid>
      <pubDate>Fri, 20 Feb 2026 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>[ç¿»è¯‘] Latent Space: Gemini 3.1 Proå‘å¸ƒï¼šARC-AGI 2æ€§èƒ½ç¿»å€</title>
      <link>https://www.latent.space/p/ainews-gemini-31-pro-2x-30-on-arc</link>
      <description>&lt;p&gt;&lt;strong&gt;æ ‡ç­¾:&lt;/strong&gt; #Gemini #åŸºå‡†æµ‹è¯• #å¤§æ¨¡å‹&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;æ‘˜è¦:&lt;/strong&gt; Googleå‘å¸ƒGemini 3.1 Proé¢„è§ˆç‰ˆï¼Œåœ¨ARC-AGI 2æ¨ç†åŸºå‡†ä¸Šå®ç°ç¿»å€çªç ´ï¼ˆè¾¾77.1%ï¼‰ï¼Œç¼–ç ä¸Agentèƒ½åŠ›å¼ºåŠ²ï¼Œå·²é€æ­¥é›†æˆè‡³Geminiåº”ç”¨åŠAPIï¼›ç¤¾åŒºè®¤å¯å…¶æ€§èƒ½è·ƒå‡ä¸å®ç”¨ä»·å€¼ï¼Œä½†ä¹ŸæŒ‡å‡ºéƒ¨åˆ†äº§å“ä¸Šçº¿å»¶è¿ŸåŠåŸºå‡†é’ˆå¯¹æ€§çš„äº‰è®®ã€‚&lt;/p&gt;
&lt;p style="color:#888;font-size:13px;"&gt;åŸæ ‡é¢˜: [AINews] Gemini 3.1 Pro: 2x 3.0 on ARC-AGI 2&lt;/p&gt;
&lt;hr/&gt;
&lt;blockquote style="border-left:3px solid #c0c0c0;padding:8px 16px;margin:8px 0;background:#f9f9fb;"&gt;
&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;
AI News for 2/18/2026-2/19/2026. We checked 12 subreddits,544 Twittersand 24 Discords (262channels, and14980messages) for you. Estimated reading time saved (at 200wpm):1467minutes.AINewsâ€™ websitelets you search all past issues. As a reminder,AINews is now a section of Latent Space. You canopt in/outof email frequencies!
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;
2026å¹´2æœˆ18æ—¥è‡³19æ—¥çš„AIæ–°é—»ã€‚æˆ‘ä»¬ä¸ºæ‚¨æ£€æŸ¥äº†12ä¸ªRedditå­ç‰ˆå—ã€544ä¸ªTwitterè´¦å·å’Œ24ä¸ªDiscordæœåŠ¡å™¨ï¼ˆ262ä¸ªé¢‘é“ï¼Œå…±14,980æ¡æ¶ˆæ¯ï¼‰ã€‚é¢„è®¡èŠ‚çœé˜…è¯»æ—¶é—´ï¼ˆæŒ‰æ¯åˆ†é’Ÿ200è¯è®¡ç®—ï¼‰ï¼š1,467åˆ†é’Ÿã€‚&lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;AINews&lt;/strong&gt;ç½‘ç«™å…è®¸æ‚¨æœç´¢æ‰€æœ‰å¾€æœŸå†…å®¹ã€‚æé†’ä¸€ä¸‹ï¼ŒAINewsç°å·²æˆä¸º&lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;Latent Space&lt;/strong&gt;çš„ä¸€ä¸ªæ ç›®ã€‚æ‚¨å¯ä»¥é€‰æ‹©æ¥æ”¶é‚®ä»¶çš„é¢‘ç‡ï¼
&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;
AI News for 2/18/2026-2/19/2026. We checked 12 subreddits,544 Twittersand 24 Discords (262channels, and14980messages) for you. Estimated reading time saved (at 200wpm):1467minutes.AINewsâ€™ websitelets you search all past issues. As a reminder,AINews is now a section of Latent Space. You canopt in/outof email frequencies!
&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;
2026å¹´2æœˆ18æ—¥è‡³19æ—¥çš„AIæ–°é—»ã€‚æˆ‘ä»¬ä¸ºæ‚¨æ£€æŸ¥äº†12ä¸ªRedditå­ç‰ˆå—ã€544ä¸ªTwitterè´¦å·å’Œ24ä¸ªDiscordæœåŠ¡å™¨ï¼ˆ262ä¸ªé¢‘é“ï¼Œå…±14,980æ¡æ¶ˆæ¯ï¼‰ã€‚é¢„è®¡èŠ‚çœé˜…è¯»æ—¶é—´ï¼ˆæŒ‰æ¯åˆ†é’Ÿ200è¯è®¡ç®—ï¼‰ï¼š1,467åˆ†é’Ÿã€‚AINewsç½‘ç«™å…è®¸æ‚¨æœç´¢æ‰€æœ‰å¾€æœŸå†…å®¹ã€‚æé†’ä¸€ä¸‹ï¼ŒAINewsç°å·²æˆä¸ºLatent Spaceçš„ä¸€ä¸ªæ ç›®ã€‚æ‚¨å¯ä»¥é€‰æ‹©æ¥æ”¶é‚®ä»¶çš„é¢‘ç‡ï¼
&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;
Itâ€™s getting a little hard to say interesting things with all the round robin minor version updates of frontier models every week, but Gemini 3.1 Pro seems like a decent enough advance to catch up, and in some cases, supercede, the fellow frontier models (this is surely the reason that 3.1 -had- to be released, because with 5.3 and 4.6 things were seriously falling behind for Google1)
&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;
éšç€å‰æ²¿æ¨¡å‹æ¯å‘¨éƒ½åœ¨è¿›è¡Œè½®ç•ªçš„å°ç‰ˆæœ¬æ›´æ–°ï¼Œè¦è¯´äº›æœ‰è¶£çš„äº‹æƒ…å˜å¾—æœ‰ç‚¹å›°éš¾ï¼Œä½†&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;Gemini 3.1 Pro&lt;/strong&gt;çœ‹èµ·æ¥æ˜¯ä¸€æ¬¡è¶³å¤Ÿä½“é¢çš„è¿›æ­¥ï¼Œèƒ½å¤Ÿè¿½èµ¶å¹¶åœ¨æŸäº›æƒ…å†µä¸‹è¶…è¶Šå…¶ä»–å‰æ²¿æ¨¡å‹ï¼ˆè¿™è‚¯å®šæ˜¯å¿…é¡»å‘å¸ƒ3.1ç‰ˆæœ¬çš„åŸå› ï¼Œå› ä¸ºåœ¨&lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;Google&lt;/strong&gt;æ¨å‡º5.3å’Œ4.6ä¹‹åï¼Œæƒ…å†µç¡®å®ä¸¥é‡è½åäº†ï¼‰ã€‚
&lt;/p&gt;

&lt;img src="https://substackcdn.com/image/fetch/$s_!yx8y!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8564929f-b251-49ac-bc93-3564e36f2cd2_2160x2700.png" alt="Image" style="max-width:100%;border-radius:8px;margin:12px 0;"/&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;
Itâ€™s better at somesvg design things:
&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;
å®ƒåœ¨æŸäº›&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;SVGè®¾è®¡&lt;/strong&gt;æ–¹é¢è¡¨ç°æ›´å¥½ï¼š
&lt;/p&gt;

&lt;img src="https://substackcdn.com/image/fetch/$s_!ccZ4!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45ca8560-c21c-4986-878f-0c6bd90275f6_1200x1078.png" alt="" style="max-width:100%;border-radius:8px;margin:12px 0;"/&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;
and translating textual vibes tovisual aesthetics:
&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;
å¹¶ä¸”åœ¨å°†æ–‡æœ¬æ°›å›´è½¬åŒ–ä¸º&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;è§†è§‰ç¾å­¦&lt;/strong&gt;æ–¹é¢ï¼š
&lt;/p&gt;

&lt;img src="https://substackcdn.com/image/fetch/$s_!LpTw!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcef6b7d8-c9db-4e5b-80db-4d65f9535c1a_1202x1082.png" alt="" style="max-width:100%;border-radius:8px;margin:12px 0;"/&gt;

&lt;h3 style="margin:24px 0 12px;"&gt;AI Twitter Recap&lt;/h3&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;
AI Twitter å›é¡¾
&lt;/p&gt;

&lt;h4 style="margin:24px 0 12px;"&gt;Top Story: Gemini 3.1 release facts and reactions/opinions&lt;/h4&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;
å¤´æ¡æ–°é—»ï¼šGemini 3.1 å‘å¸ƒçš„äº‹å®ä¸ååº”/è§‚ç‚¹
&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;
Google shippedGemini 3.1 Pro(generally described as aPreviewfor developers) and rolled it out across theGemini app,NotebookLM,Gemini API / AI Studio, andVertex AI, positioning it as the â€œcore intelligenceâ€ fromGemini 3 Deep Thinkscaled down for practical product use. The announcement emphasized a big reasoning jumpâ€”especiallyARC-AGI-2 = 77.1%â€”plus strong coding and agentic-tool benchmarks (e.g.,SWE-Bench Verified = 80.6%) and improved hallucination behavior. Independent leaderboards and evaluators largely corroborated top-tier performance and strong cost/intelligence positioning, while reaction threads highlighted (a) excitement about practical gains (SVG/web/UI/code quality, agentic use cases), (b) skepticism about benchmark-targeting and â€œeval tweeting,â€ (c) concerns aroundGDPval(real-world agentic tasks) not leading despite other SOTA scores, and (d) rollout friction: users finding some products (Gemini CLI / Code Assist / Antigravity) unavailable or inconsistently updated at launch.
&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;
&lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;Google&lt;/strong&gt;å‘å¸ƒäº†&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;Gemini 3.1 Pro&lt;/strong&gt;ï¼ˆé€šå¸¸è¢«æè¿°ä¸ºé¢å‘å¼€å‘è€…çš„é¢„è§ˆç‰ˆï¼‰ï¼Œå¹¶å°†å…¶æ¨å¹¿è‡³Geminiåº”ç”¨ã€NotebookLMã€Gemini API / AI Studioå’ŒVertex AIï¼Œå°†å…¶å®šä½ä¸ºGemini 3 Deep Thinkçš„"æ ¸å¿ƒæ™ºèƒ½"ç»ç¼©æ”¾åç”¨äºå®é™…äº§å“ã€‚å…¬å‘Šå¼ºè°ƒäº†ä¸€æ¬¡å·¨å¤§çš„æ¨ç†èƒ½åŠ›æå‡â€”â€”ç‰¹åˆ«æ˜¯&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;ARC-AGI-2&lt;/strong&gt;è¾¾åˆ°77.1%â€”â€”ä»¥åŠå¼ºå¤§çš„ç¼–ç å’ŒAgenticï¼ˆæ™ºèƒ½ä½“ï¼‰å·¥å…·åŸºå‡†æµ‹è¯•ï¼ˆä¾‹å¦‚&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;SWE-Bench Verified&lt;/strong&gt;è¾¾åˆ°80.6%ï¼‰å’Œæ”¹è¿›çš„å¹»è§‰è¡Œä¸ºã€‚ç‹¬ç«‹çš„æ’è¡Œæ¦œå’Œè¯„ä¼°è€…åŸºæœ¬è¯å®äº†å…¶é¡¶çº§æ€§èƒ½å’Œå¼ºå¤§çš„æˆæœ¬/æ™ºèƒ½æ¯”å®šä½ï¼Œè€Œååº”å¸–æ–‡åˆ™å¼ºè°ƒï¼šï¼ˆaï¼‰å¯¹å®é™…åº”ç”¨æ”¶ç›Šï¼ˆSVG/ç½‘é¡µ/UI/ä»£ç è´¨é‡ã€Agenticåº”ç”¨åœºæ™¯ï¼‰çš„å…´å¥‹ï¼Œï¼ˆbï¼‰å¯¹é’ˆå¯¹åŸºå‡†æµ‹è¯•å’Œ"è¯„ä¼°æ¨æ–‡"çš„æ€€ç–‘ï¼Œï¼ˆcï¼‰å°½ç®¡å…¶ä»–SOTAï¼ˆState of the Artï¼Œæœ€å…ˆè¿›çš„ï¼‰åˆ†æ•°é¢†å…ˆï¼Œä½†GDPvalï¼ˆç°å®ä¸–ç•ŒAgenticä»»åŠ¡ï¼‰æœªèƒ½é¢†å…ˆçš„æ‹…å¿§ï¼Œä»¥åŠï¼ˆdï¼‰æ¨å¹¿é˜»åŠ›ï¼šç”¨æˆ·å‘ç°æŸäº›äº§å“ï¼ˆGemini CLI / Code Assist / Antigravityï¼‰åœ¨å‘å¸ƒæ—¶ä¸å¯ç”¨æˆ–æ›´æ–°ä¸ä¸€è‡´ã€‚
&lt;/p&gt;

&lt;h4 style="margin:24px 0 12px;"&gt;Facts vs. opinions&lt;/h4&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;
äº‹å®ä¸è§‚ç‚¹
&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;
Read more
&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;
é˜…è¯»æ›´å¤š
&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;ğŸ”— &lt;a href="https://www.latent.space/p/ainews-gemini-31-pro-2x-30-on-arc"&gt;é˜…è¯»åŸæ–‡&lt;/a&gt;&lt;/p&gt;</description>
      <guid isPermaLink="false">https://www.latent.space/p/ainews-gemini-31-pro-2x-30-on-arc</guid>
      <pubDate>Fri, 20 Feb 2026 07:15:49 +0000</pubDate>
    </item>
    <item>
      <title>[ç¿»è¯‘] Simon Willison: ä»£ç å¤±è€Œå¤å¾—</title>
      <link>https://simonwillison.net/2026/Feb/19/recovering-lost-code/#atom-everything</link>
      <description>&lt;p&gt;&lt;strong&gt;æ ‡ç­¾:&lt;/strong&gt; #ä»£ç æ¢å¤ #AIç¼–ç¨‹ #å¹¶è¡Œä»£ç†&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;æ‘˜è¦:&lt;/strong&gt; ä½œè€…åœ¨ä½¿ç”¨å¹¶è¡ŒAIæ™ºèƒ½ä½“ç¼–ç¨‹æ—¶ï¼Œå› ç”µè„‘å´©æºƒä¸¢å¤±äº†å­˜å‚¨åœ¨ä¸´æ—¶ç›®å½•ä¸­çš„ä»£ç åŠŸèƒ½ï¼Œæœ€ç»ˆé€šè¿‡Claude Codeçš„ä¼šè¯æ—¥å¿—æˆåŠŸæ¢å¤ã€‚&lt;/p&gt;
&lt;p style="color:#888;font-size:13px;"&gt;åŸæ ‡é¢˜: Recovering lost code&lt;/p&gt;
&lt;hr/&gt;
&lt;h3 style="margin:24px 0 12px;"&gt;Recovering lost code / æ¢å¤ä¸¢å¤±çš„ä»£ç &lt;/h3&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;Reached the stage of &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;parallel agent psychosis&lt;/strong&gt; where I've lost a whole &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;feature&lt;/strong&gt; - I know I had it yesterday, but I can't seem to find the &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;branch&lt;/strong&gt; or &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;worktree&lt;/strong&gt; or &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;cloud instance&lt;/strong&gt; or &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;checkout&lt;/strong&gt; with it in.&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;æˆ‘å·²ç»è¿›å…¥äº†&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;å¹¶è¡Œæ™ºèƒ½ä½“ç²¾ç¥é”™ä¹±&lt;/strong&gt;ï¼ˆparallel agent psychosisï¼‰çš„é˜¶æ®µï¼Œä»¥è‡³äºä¸¢å¤±äº†æ•´ä¸ª&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;åŠŸèƒ½ç‰¹æ€§&lt;/strong&gt;ï¼ˆfeatureï¼‰â€”â€”æˆ‘ç¡®ä¿¡æ˜¨å¤©è¿˜åœ¨çš„ï¼Œå´æ€ä¹ˆä¹Ÿæ‰¾ä¸åˆ°åŒ…å«å®ƒçš„&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;åˆ†æ”¯&lt;/strong&gt;ï¼ˆbranchï¼‰ã€&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;å·¥ä½œæ ‘&lt;/strong&gt;ï¼ˆworktreeï¼‰ã€&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;äº‘å®ä¾‹&lt;/strong&gt;ï¼ˆcloud instanceï¼‰æˆ–&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;æ£€å‡º&lt;/strong&gt;ï¼ˆcheckoutï¼‰äº†ã€‚&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;... found it! Turns out I'd been hacking on a random &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;prototype&lt;/strong&gt; in &lt;code style="background:#f0f0f5;padding:2px 6px;border-radius:4px;font-size:13px;"&gt;/tmp&lt;/code&gt; and then my computer crashed and rebooted and I lost the code... but it's all still there in &lt;code style="background:#f0f0f5;padding:2px 6px;border-radius:4px;font-size:13px;"&gt;~/.claude/projects/session logs&lt;/code&gt; and &lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;Claude Code&lt;/strong&gt; can extract it out and spin up the missing feature again.&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;â€¦â€¦æ‰¾åˆ°äº†ï¼åŸæ¥æˆ‘ä¹‹å‰ä¸€ç›´åœ¨&lt;code style="background:#f0f0f5;padding:2px 6px;border-radius:4px;font-size:13px;"&gt;/tmp&lt;/code&gt;ç›®å½•é‡Œéšæ„å¼€å‘ä¸€ä¸ª&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;åŸå‹&lt;/strong&gt;ï¼ˆprototypeï¼‰ï¼Œç„¶åç”µè„‘å´©æºƒé‡å¯ï¼Œä»£ç å°±ä¸¢äº†â€¦â€¦ä½†æ‰€æœ‰å†…å®¹éƒ½è¿˜åœ¨&lt;code style="background:#f0f0f5;padding:2px 6px;border-radius:4px;font-size:13px;"&gt;~/.claude/projects/session logs&lt;/code&gt;é‡Œï¼Œè€Œä¸”&lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;Claude Code&lt;/strong&gt;èƒ½å¤Ÿå°†å…¶æå–å‡ºæ¥ï¼Œå¹¶é‡æ–°å¯åŠ¨é‚£ä¸ªä¸¢å¤±çš„åŠŸèƒ½ã€‚&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;Tags: &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;parallel-agents&lt;/strong&gt;, &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;coding-agents&lt;/strong&gt;, &lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;claude-code&lt;/strong&gt;, &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;generative-ai&lt;/strong&gt;, &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;ai&lt;/strong&gt;, &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;llms&lt;/strong&gt;&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;æ ‡ç­¾ï¼š&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;å¹¶è¡Œæ™ºèƒ½ä½“&lt;/strong&gt;ï¼ˆparallel-agentsï¼‰ã€&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;ç¼–ç¨‹æ™ºèƒ½ä½“&lt;/strong&gt;ï¼ˆcoding-agentsï¼‰ã€&lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;Claude Code&lt;/strong&gt;ã€&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;ç”Ÿæˆå¼ AI&lt;/strong&gt;ï¼ˆgenerative-aiï¼‰ã€&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;äººå·¥æ™ºèƒ½&lt;/strong&gt;ï¼ˆaiï¼‰ã€&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;å¤§è¯­è¨€æ¨¡å‹&lt;/strong&gt;ï¼ˆllmsï¼‰&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;ğŸ”— &lt;a href="https://simonwillison.net/2026/Feb/19/recovering-lost-code/#atom-everything"&gt;é˜…è¯»åŸæ–‡&lt;/a&gt;&lt;/p&gt;</description>
      <guid isPermaLink="false">https://simonwillison.net/2026/Feb/19/recovering-lost-code/#atom-everything</guid>
      <pubDate>Thu, 19 Feb 2026 23:48:35 +0000</pubDate>
    </item>
    <item>
      <title>[ç¿»è¯‘] Simon Willison: Claude Code çš„æç¤ºç¼“å­˜å·¥ç¨‹å®è·µ</title>
      <link>https://simonwillison.net/2026/Feb/20/thariq-shihipar/#atom-everything</link>
      <description>&lt;p&gt;&lt;strong&gt;æ ‡ç­¾:&lt;/strong&gt; #æç¤ºç¼“å­˜ #AIä»£ç† #æˆæœ¬ä¼˜åŒ–&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;æ‘˜è¦:&lt;/strong&gt; Anthropicå·¥ç¨‹å¸ˆThariq ShihiparæŒ‡å‡ºï¼Œæç¤ºè¯ç¼“å­˜æŠ€æœ¯é€šè¿‡å¤ç”¨å†å²è®¡ç®—æ˜¾è‘—é™ä½å»¶è¿Ÿä¸æˆæœ¬ï¼Œä½¿Claude Codeç­‰é•¿æ—¶æ™ºèƒ½ä½“äº§å“æˆä¸ºå¯èƒ½ï¼›è¯¥å›¢é˜Ÿå›´ç»•ç¼“å­˜æ„å»ºæ•´å¥—ç³»ç»Ÿæ¶æ„ï¼Œå¹¶å°†å…¶å‘½ä¸­ç‡è§†ä¸ºå…³é”®æœåŠ¡æŒ‡æ ‡ï¼Œè¿‡ä½æ—¶ç”šè‡³ä¼šè§¦å‘ä¸¥é‡äº‹æ•…è­¦æŠ¥ã€‚&lt;/p&gt;
&lt;p style="color:#888;font-size:13px;"&gt;åŸæ ‡é¢˜: Quoting Thariq Shihipar&lt;/p&gt;
&lt;hr/&gt;
&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;
&lt;blockquote style="border-left:3px solid #c0c0c0;padding:8px 16px;margin:8px 0;background:#f9f9fb;"&gt;
Long running &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;agentic products&lt;/strong&gt; like &lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;Claude Code&lt;/strong&gt; are made feasible by &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;prompt caching&lt;/strong&gt; which allows us to reuse computation from previous roundtrips and significantly decrease latency and cost. [...]
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;
è¯¸å¦‚ &lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;Claude Code&lt;/strong&gt; ä¹‹ç±»çš„&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;é•¿æ—¶é—´è¿è¡Œæ™ºèƒ½ä½“äº§å“&lt;/strong&gt;ï¼ˆLong running agentic productsï¼‰ä¹‹æ‰€ä»¥èƒ½å¤Ÿå®ç°ï¼Œå¾—ç›Šäº&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;æç¤ºè¯ç¼“å­˜&lt;/strong&gt;ï¼ˆprompt cachingï¼‰æŠ€æœ¯ï¼Œå®ƒä½¿æˆ‘ä»¬èƒ½å¤Ÿå¤ç”¨å…ˆå‰äº¤äº’å›åˆï¼ˆroundtripsï¼‰ä¸­çš„è®¡ç®—ç»“æœï¼Œä»è€Œæ˜¾è‘—é™ä½å»¶è¿Ÿå’Œæˆæœ¬ã€‚[...]
&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;
At &lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;Claude Code&lt;/strong&gt;, we build our entire harness around &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;prompt caching&lt;/strong&gt;. A high &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;prompt cache hit rate&lt;/strong&gt; decreases costs and helps us create more generous &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;rate limits&lt;/strong&gt; for our subscription plans, so we run alerts on our prompt cache hit rate and declare &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;SEVs&lt;/strong&gt; if they're too low.
&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;
åœ¨ &lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;Claude Code&lt;/strong&gt; ä¸­ï¼Œæˆ‘ä»¬å›´ç»•&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;æç¤ºè¯ç¼“å­˜&lt;/strong&gt;ï¼ˆprompt cachingï¼‰æ„å»ºäº†å®Œæ•´çš„æ”¯æ’‘æ¶æ„ï¼ˆharnessï¼‰ã€‚è¾ƒé«˜çš„&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;ç¼“å­˜å‘½ä¸­ç‡&lt;/strong&gt;ï¼ˆcache hit rateï¼‰èƒ½å¤Ÿé™ä½æˆæœ¬ï¼Œå¹¶å¸®åŠ©æˆ‘ä»¬ä¸ºè®¢é˜…è®¡åˆ’è®¾ç½®æ›´å®½æ¾çš„&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;é€Ÿç‡é™åˆ¶&lt;/strong&gt;ï¼ˆrate limitsï¼‰ï¼Œå› æ­¤æˆ‘ä»¬ä¼šé’ˆå¯¹ç¼“å­˜å‘½ä¸­ç‡è®¾ç½®ç›‘æ§å‘Šè­¦ï¼Œå¹¶åœ¨å‘½ä¸­ç‡è¿‡ä½æ—¶å®£å¸ƒ&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;é‡å¤§äº‹æ•…&lt;/strong&gt;ï¼ˆSEVsï¼ŒSite Eventsï¼‰ã€‚
&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;
â€”&lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;Thariq Shihipar&lt;/strong&gt;
&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;
â€”â€”&lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;Thariq Shihipar&lt;/strong&gt;ï¼ˆ&lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;Anthropic&lt;/strong&gt; å·¥ç¨‹å¸ˆï¼‰
&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;
Tags: &lt;code style="background:#f0f0f5;padding:2px 6px;border-radius:4px;font-size:13px;"&gt;prompt-engineering&lt;/code&gt;, &lt;code style="background:#f0f0f5;padding:2px 6px;border-radius:4px;font-size:13px;"&gt;anthropic&lt;/code&gt;, &lt;code style="background:#f0f0f5;padding:2px 6px;border-radius:4px;font-size:13px;"&gt;claude-code&lt;/code&gt;, &lt;code style="background:#f0f0f5;padding:2px 6px;border-radius:4px;font-size:13px;"&gt;ai-agents&lt;/code&gt;, &lt;code style="background:#f0f0f5;padding:2px 6px;border-radius:4px;font-size:13px;"&gt;generative-ai&lt;/code&gt;, &lt;code style="background:#f0f0f5;padding:2px 6px;border-radius:4px;font-size:13px;"&gt;ai&lt;/code&gt;, &lt;code style="background:#f0f0f5;padding:2px 6px;border-radius:4px;font-size:13px;"&gt;llms&lt;/code&gt;
&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;
æ ‡ç­¾ï¼š&lt;code style="background:#f0f0f5;padding:2px 6px;border-radius:4px;font-size:13px;"&gt;prompt-engineeringï¼ˆæç¤ºå·¥ç¨‹ï¼‰&lt;/code&gt;ã€&lt;code style="background:#f0f0f5;padding:2px 6px;border-radius:4px;font-size:13px;"&gt;anthropic&lt;/code&gt;ã€&lt;code style="background:#f0f0f5;padding:2px 6px;border-radius:4px;font-size:13px;"&gt;claude-code&lt;/code&gt;ã€&lt;code style="background:#f0f0f5;padding:2px 6px;border-radius:4px;font-size:13px;"&gt;ai-agentsï¼ˆAI æ™ºèƒ½ä½“ï¼‰&lt;/code&gt;ã€&lt;code style="background:#f0f0f5;padding:2px 6px;border-radius:4px;font-size:13px;"&gt;generative-aiï¼ˆç”Ÿæˆå¼ AIï¼‰&lt;/code&gt;ã€&lt;code style="background:#f0f0f5;padding:2px 6px;border-radius:4px;font-size:13px;"&gt;aiï¼ˆäººå·¥æ™ºèƒ½ï¼‰&lt;/code&gt;ã€&lt;code style="background:#f0f0f5;padding:2px 6px;border-radius:4px;font-size:13px;"&gt;llmsï¼ˆå¤§è¯­è¨€æ¨¡å‹ï¼‰&lt;/code&gt;
&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;ğŸ”— &lt;a href="https://simonwillison.net/2026/Feb/20/thariq-shihipar/#atom-everything"&gt;é˜…è¯»åŸæ–‡&lt;/a&gt;&lt;/p&gt;</description>
      <guid isPermaLink="false">https://simonwillison.net/2026/Feb/20/thariq-shihipar/#atom-everything</guid>
      <pubDate>Fri, 20 Feb 2026 07:13:19 +0000</pubDate>
    </item>
    <item>
      <title>[ç¿»è¯‘] Simon Willison: ggml.ai åŠ å…¥ Hugging Faceï¼Œç¡®ä¿æœ¬åœ° AI é•¿æœŸå‘å±•</title>
      <link>https://simonwillison.net/2026/Feb/20/ggmlai-joins-hugging-face/#atom-everything</link>
      <description>&lt;p&gt;&lt;strong&gt;æ ‡ç­¾:&lt;/strong&gt; #æœ¬åœ°AI #å¼€æº #å¤§æ¨¡å‹&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;æ‘˜è¦:&lt;/strong&gt; ggml.aiï¼ˆllama.cppå¼€å‘å›¢é˜Ÿï¼‰åŠ å…¥Hugging Faceï¼ŒåŒæ–¹å°†é€šè¿‡ä¸Transformersåº“çš„æ— ç¼é›†æˆåŠæ”¹å–„è½¯ä»¶ç”¨æˆ·ä½“éªŒï¼Œå…±åŒæ¨åŠ¨æœ¬åœ°AIæ¨¡å‹çš„é•¿æœŸå‘å±•ä¸æ™®åŠã€‚&lt;/p&gt;
&lt;p style="color:#888;font-size:13px;"&gt;åŸæ ‡é¢˜: ggml.ai joins Hugging Face to ensure the long-term progress of Local AI&lt;/p&gt;
&lt;hr/&gt;
&lt;h3 style="margin:24px 0 12px;"&gt;ggml.ai joins Hugging Face to ensure the long-term progress of Local AI&lt;/h3&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;&lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;ggml.ai&lt;/strong&gt; åŠ å…¥ &lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;Hugging Face&lt;/strong&gt;ï¼Œä»¥ç¡®ä¿&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;æœ¬åœ° AI&lt;/strong&gt;ï¼ˆLocal AIï¼‰çš„é•¿æœŸå‘å±•&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;It's hard to overstate the impact &lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;Georgi Gerganov&lt;/strong&gt; has had on the &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;local model&lt;/strong&gt; space. Back in March 2023 his release of&lt;strong&gt;llama.cpp&lt;/strong&gt;made it possible to run a local&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;LLM&lt;/strong&gt;on&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;consumer hardware&lt;/strong&gt;. The&lt;strong&gt;original README&lt;/strong&gt;said:&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;å¾ˆéš¾å¤¸å¤§ &lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;Georgi Gerganov&lt;/strong&gt; å¯¹&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;æœ¬åœ°æ¨¡å‹&lt;/strong&gt;ï¼ˆlocal modelï¼‰é¢†åŸŸäº§ç”Ÿçš„å½±å“ã€‚æ—©åœ¨ 2023 å¹´ 3 æœˆï¼Œä»–å‘å¸ƒçš„ &lt;strong&gt;llama.cpp&lt;/strong&gt; ä½¿å¾—åœ¨&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;æ¶ˆè´¹çº§ç¡¬ä»¶&lt;/strong&gt;ï¼ˆconsumer hardwareï¼‰ä¸Šè¿è¡Œæœ¬åœ°&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;å¤§è¯­è¨€æ¨¡å‹&lt;/strong&gt;ï¼ˆLLM, Large Language Modelï¼‰æˆä¸ºå¯èƒ½ã€‚å…¶&lt;strong&gt;åŸå§‹ README&lt;/strong&gt; å†™é“ï¼š&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;&lt;blockquote style="border-left:3px solid #c0c0c0;padding:8px 16px;margin:8px 0;background:#f9f9fb;"&gt;The main goal is to run the model using&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;4-bit quantization&lt;/strong&gt;on a MacBook. [...] This was hacked in an evening - I have no idea if it works correctly.&lt;/blockquote&gt;&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;ä¸»è¦ç›®æ ‡æ˜¯åœ¨ MacBook ä¸Šä½¿ç”¨&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;4-bit é‡åŒ–&lt;/strong&gt;ï¼ˆ4-bit quantizationï¼‰æŠ€æœ¯è¿è¡Œæ¨¡å‹ã€‚[...] è¿™æ˜¯ä¸€ä¸ªæ™šä¸Š hack å‡ºæ¥çš„äº§ç‰©â€”â€”æˆ‘ä¸çŸ¥é“å®ƒæ˜¯å¦èƒ½æ­£å¸¸å·¥ä½œã€‚&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;I wrote about trying&lt;strong&gt;llama.cpp&lt;/strong&gt;out at the time in&lt;strong&gt;Large language models are having their Stable Diffusion moment&lt;/strong&gt;:&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;æˆ‘å½“æ—¶åœ¨ã€ŠLarge language models are having their Stable Diffusion momentã€‹ä¸€æ–‡ä¸­å†™åˆ°äº†è¯•ç”¨ &lt;strong&gt;llama.cpp&lt;/strong&gt; çš„ç»å†ï¼š&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;&lt;blockquote style="border-left:3px solid #c0c0c0;padding:8px 16px;margin:8px 0;background:#f9f9fb;"&gt;I used it to run the&lt;strong&gt;7B LLaMA&lt;/strong&gt;model on my laptop last night, and then this morning upgraded to the&lt;strong&gt;13B model&lt;/strong&gt;â€”the one that&lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;Facebook&lt;/strong&gt;claim is competitive with&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;GPT-3&lt;/strong&gt;.&lt;/blockquote&gt;&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;æ˜¨æ™šæˆ‘ç”¨å®ƒåœ¨ç¬”è®°æœ¬ç”µè„‘ä¸Šè¿è¡Œäº† 70 äº¿å‚æ•°çš„ &lt;strong&gt;LLaMA&lt;/strong&gt; æ¨¡å‹ï¼Œä»Šå¤©æ—©ä¸Šå‡çº§åˆ°äº† 130 äº¿å‚æ•°ç‰ˆæœ¬â€”â€”ä¹Ÿå°±æ˜¯ &lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;Facebook&lt;/strong&gt;ï¼ˆç° &lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;Meta&lt;/strong&gt;ï¼‰å£°ç§°èƒ½ä¸ &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;GPT-3&lt;/strong&gt; ç«äº‰çš„æ¨¡å‹ã€‚&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;&lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;Meta&lt;/strong&gt;'s&lt;strong&gt;original LLaMA release&lt;/strong&gt;depended on&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;PyTorch&lt;/strong&gt;and their&lt;strong&gt;FairScale&lt;/strong&gt;PyTorch extension for running on multiple GPUs, and required&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;CUDA&lt;/strong&gt;and&lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;NVIDIA&lt;/strong&gt;hardware. Georgi's work opened that up to a much wider range of hardware and kicked off the local model movement that has continued to grow since then.&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;&lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;Meta&lt;/strong&gt; çš„&lt;strong&gt;åŸå§‹ LLaMA å‘å¸ƒ&lt;/strong&gt;ä¾èµ–äº &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;PyTorch&lt;/strong&gt; åŠå…¶ &lt;strong&gt;FairScale&lt;/strong&gt; PyTorch æ‰©å±•æ¥åœ¨å¤š GPU ä¸Šè¿è¡Œï¼Œå¹¶ä¸”éœ€è¦ &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;CUDA&lt;/strong&gt; å’Œ &lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;NVIDIA&lt;/strong&gt; ç¡¬ä»¶ã€‚è€Œ Georgi çš„å·¥ä½œå°†å…¶å¼€æ”¾ç»™äº†èŒƒå›´æ›´å¹¿çš„ç¡¬ä»¶ï¼Œå¹¶ç”±æ­¤æ‹‰å¼€äº†æœ¬åœ°æ¨¡å‹è¿åŠ¨çš„åºå¹•ï¼Œè¯¥è¿åŠ¨æ­¤åæŒç»­å‘å±•å£®å¤§ã€‚&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;&lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;Hugging Face&lt;/strong&gt;are already responsible for the incredibly influential&lt;strong&gt;Transformers&lt;/strong&gt;library used by the majority of LLM releases today. They've proven themselves a good steward for that&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;open source&lt;/strong&gt;project, which makes me optimistic for the future of&lt;strong&gt;llama.cpp&lt;/strong&gt;and related projects.&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;&lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;Hugging Face&lt;/strong&gt; å·²ç»è´Ÿè´£ç»´æŠ¤ç€æå…·å½±å“åŠ›çš„ &lt;strong&gt;Transformers&lt;/strong&gt; åº“ï¼Œè¯¥åº“è¢«å½“ä»Šå¤§å¤šæ•° LLM å‘å¸ƒæ‰€ä½¿ç”¨ã€‚ä»–ä»¬å·²è¯æ˜è‡ªå·±æ˜¯è¿™ä¸ª&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;å¼€æº&lt;/strong&gt;ï¼ˆopen sourceï¼‰é¡¹ç›®çš„ä¼˜ç§€ç®¡ç†è€…ï¼Œè¿™è®©æˆ‘å¯¹ &lt;strong&gt;llama.cpp&lt;/strong&gt; åŠç›¸å…³é¡¹ç›®çš„æœªæ¥æ„Ÿåˆ°ä¹è§‚ã€‚&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;This section from the announcement looks particularly promising:&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;å…¬å‘Šä¸­çš„è¿™ä¸€æ®µçœ‹èµ·æ¥ç‰¹åˆ«æœ‰å‰æ™¯ï¼š&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;&lt;blockquote style="border-left:3px solid #c0c0c0;padding:8px 16px;margin:8px 0;background:#f9f9fb;"&gt;Going forward, our joint efforts will be geared towards the following objectives:
&lt;ul style="margin:8px 0;padding-left:24px;"&gt;
&lt;li&gt;Towards seamless "single-click" integration with the&lt;strong&gt;transformers&lt;/strong&gt;library. The&lt;strong&gt;transformers&lt;/strong&gt;framework has established itself as the 'source of truth' for AI model definitions. Improving the compatibility between the transformers and the&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;ggml&lt;/strong&gt;ecosystems is essential for wider model support and quality control.&lt;/li&gt;
&lt;li&gt;Better packaging and user experience of&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;ggml&lt;/strong&gt;-based software. As we enter the phase in which&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;local inference&lt;/strong&gt;becomes a meaningful and competitive alternative to&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;cloud inference&lt;/strong&gt;, it is crucial to improve and simplify the way in which casual users deploy and access local models. We will work towards making&lt;strong&gt;llama.cpp&lt;/strong&gt;ubiquitous and readily available everywhere, and continue partnering with great downstream projects.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;&lt;/div&gt;
&lt;div style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;
&lt;p style="margin:0 0 8px 0;"&gt;å±•æœ›æœªæ¥ï¼Œæˆ‘ä»¬çš„å…±åŒåŠªåŠ›å°†å›´ç»•ä»¥ä¸‹ç›®æ ‡å±•å¼€ï¼š&lt;/p&gt;
&lt;ul style="margin:0;padding-left:24px;"&gt;
&lt;li&gt;å®ç°ä¸ &lt;strong&gt;transformers&lt;/strong&gt; åº“çš„æ— ç¼"ä¸€é”®å¼"é›†æˆã€‚&lt;strong&gt;transformers&lt;/strong&gt; æ¡†æ¶å·²æˆä¸º AI æ¨¡å‹å®šä¹‰çš„"äº‹å®æ ‡å‡†"ï¼ˆsource of truthï¼‰ã€‚æå‡ transformers ä¸ &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;ggml&lt;/strong&gt; ç”Ÿæ€ç³»ç»Ÿä¹‹é—´çš„å…¼å®¹æ€§ï¼Œå¯¹äºæ›´å¹¿æ³›çš„æ¨¡å‹æ”¯æŒå’Œè´¨é‡æ§åˆ¶è‡³å…³é‡è¦ã€‚&lt;/li&gt;
&lt;li&gt;æ”¹è¿›åŸºäº &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;ggml&lt;/strong&gt; çš„è½¯ä»¶çš„æ‰“åŒ…æ–¹å¼å’Œç”¨æˆ·ä½“éªŒã€‚éšç€æˆ‘ä»¬è¿›å…¥&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;æœ¬åœ°æ¨ç†&lt;/strong&gt;ï¼ˆlocal inferenceï¼‰æˆä¸º&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;äº‘ç«¯æ¨ç†&lt;/strong&gt;ï¼ˆcloud inferenceï¼‰çš„æœ‰æ„ä¹‰ä¸”å…·ç«äº‰åŠ›çš„æ›¿ä»£æ–¹æ¡ˆçš„é˜¶æ®µï¼Œæ”¹è¿›å’Œç®€åŒ–æ™®é€šç”¨æˆ·éƒ¨ç½²å’Œè®¿é—®æœ¬åœ°æ¨¡å‹çš„æ–¹å¼å˜å¾—è‡³å…³é‡è¦ã€‚æˆ‘ä»¬å°†è‡´åŠ›äºä½¿ &lt;strong&gt;llama.cpp&lt;/strong&gt; æ— å¤„ä¸åœ¨ä¸”éšæ—¶å¯ç”¨ï¼Œå¹¶ç»§ç»­ä¸ä¼˜ç§€çš„ä¸‹æ¸¸é¡¹ç›®åˆä½œã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;Given the influence of&lt;strong&gt;Transformers&lt;/strong&gt;, this closer integration could lead to model releases that are compatible with the&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;GGML&lt;/strong&gt;ecosystem out of the box. That would be a big win for the local model ecosystem.&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;é‰´äº &lt;strong&gt;Transformers&lt;/strong&gt; çš„å½±å“åŠ›ï¼Œè¿™ç§æ›´ç´§å¯†çš„é›†æˆå¯èƒ½ä¼šä¿ƒä½¿å‘å¸ƒçš„æ¨¡å‹&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;å¼€ç®±å³ç”¨&lt;/strong&gt;ï¼ˆout of the boxï¼‰åœ°å…¼å®¹ &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;GGML&lt;/strong&gt; ç”Ÿæ€ç³»ç»Ÿã€‚è¿™å°†æˆä¸ºæœ¬åœ°æ¨¡å‹ç”Ÿæ€ç³»ç»Ÿçš„ä¸€å¤§èƒœåˆ©ã€‚&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;I'm also excited to see investment in "packaging and user experience of&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;ggml&lt;/strong&gt;-based software". This has mostly been left to tools like&lt;strong&gt;Ollama&lt;/strong&gt;and&lt;strong&gt;LM Studio&lt;/strong&gt;.&lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;ggml-org&lt;/strong&gt;released&lt;strong&gt;LlamaBarn&lt;/strong&gt;last year - "a macOS menu bar app for running local LLMs" - and I'm hopeful that further investment in this area will result in more high quality&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;open source&lt;/strong&gt;tools for running local models from the team best placed to deliver them.&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;æˆ‘ä¹Ÿå¾ˆé«˜å…´çœ‹åˆ°å¯¹"åŸºäº &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;ggml&lt;/strong&gt; çš„è½¯ä»¶æ‰“åŒ…å’Œç”¨æˆ·ä½“éªŒ"çš„æŠ•å…¥ã€‚è¿™æ–¹é¢æ­¤å‰ä¸»è¦ç•™ç»™äº† &lt;strong&gt;Ollama&lt;/strong&gt; å’Œ &lt;strong&gt;LM Studio&lt;/strong&gt; ç­‰å·¥å…·ã€‚&lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;ggml-org&lt;/strong&gt; å»å¹´å‘å¸ƒäº† &lt;strong&gt;LlamaBarn&lt;/strong&gt;â€”â€”ä¸€æ¬¾"ç”¨äºè¿è¡Œæœ¬åœ° LLM çš„ macOS èœå•æ åº”ç”¨"â€”â€”æˆ‘å¸Œæœ›åœ¨è¿™ä¸€é¢†åŸŸçš„è¿›ä¸€æ­¥æŠ•å…¥ï¼Œèƒ½å¤Ÿç”±æœ€é€‚åˆçš„å›¢é˜Ÿå¼€å‘å‡ºæ›´å¤šç”¨äºè¿è¡Œæœ¬åœ°æ¨¡å‹çš„é«˜è´¨é‡&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;å¼€æº&lt;/strong&gt;ï¼ˆopen sourceï¼‰å·¥å…·ã€‚&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;Via&lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;@ggerganov&lt;/strong&gt;&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;æ¥è‡ª &lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;@ggerganov&lt;/strong&gt;&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;Tags:&lt;strong&gt;open-source&lt;/strong&gt;,&lt;strong&gt;transformers&lt;/strong&gt;,&lt;strong&gt;ai&lt;/strong&gt;,&lt;strong&gt;generative-ai&lt;/strong&gt;,&lt;strong&gt;llama&lt;/strong&gt;,&lt;strong&gt;local-llms&lt;/strong&gt;,&lt;strong&gt;llms&lt;/strong&gt;,&lt;strong&gt;hugging-face&lt;/strong&gt;,&lt;strong&gt;llama-cpp&lt;/strong&gt;&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;æ ‡ç­¾ï¼š&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;å¼€æº&lt;/strong&gt;ï¼ˆopen-sourceï¼‰ã€&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;transformers&lt;/strong&gt;ã€&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;äººå·¥æ™ºèƒ½&lt;/strong&gt;ï¼ˆaiï¼‰ã€&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;ç”Ÿæˆå¼ AI&lt;/strong&gt;ï¼ˆgenerative-aiï¼‰ã€&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;llama&lt;/strong&gt;ã€&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;æœ¬åœ° LLM&lt;/strong&gt;ï¼ˆlocal-llmsï¼‰ã€&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;å¤§è¯­è¨€æ¨¡å‹&lt;/strong&gt;ï¼ˆllmsï¼‰ã€&lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;Hugging Face&lt;/strong&gt;ã€&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;llama-cpp&lt;/strong&gt;&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;ğŸ”— &lt;a href="https://simonwillison.net/2026/Feb/20/ggmlai-joins-hugging-face/#atom-everything"&gt;é˜…è¯»åŸæ–‡&lt;/a&gt;&lt;/p&gt;</description>
      <guid isPermaLink="false">https://simonwillison.net/2026/Feb/20/ggmlai-joins-hugging-face/#atom-everything</guid>
      <pubDate>Fri, 20 Feb 2026 17:12:55 +0000</pubDate>
    </item>
    <item>
      <title>[ç¿»è¯‘] Simon Willison: Taalas å®ç° Llama 3.1 8B æ¯ç§’ 1.7 ä¸‡ Token æé€Ÿæ¨ç†</title>
      <link>https://simonwillison.net/2026/Feb/20/taalas/#atom-everything</link>
      <description>&lt;p&gt;&lt;strong&gt;æ ‡ç­¾:&lt;/strong&gt; #AIç¡¬ä»¶ #æ¨ç†åŠ é€Ÿ #æ¨¡å‹é‡åŒ–&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;æ‘˜è¦:&lt;/strong&gt; åŠ æ‹¿å¤§ç¡¬ä»¶åˆåˆ›å…¬å¸Taalaså‘å¸ƒé¦–æ¬¾AIèŠ¯ç‰‡ï¼Œä»¥æ¯ç§’17,000ä¸ªtokençš„è¶…é«˜é€Ÿåº¦è¿è¡ŒLlama 3.1 8Bæ¨¡å‹ï¼Œé€šè¿‡3-bitä¸6-bitæ··åˆçš„æ¿€è¿›é‡åŒ–æŠ€æœ¯å®ç°æè‡´æ¨ç†æ€§èƒ½ã€‚&lt;/p&gt;
&lt;p style="color:#888;font-size:13px;"&gt;åŸæ ‡é¢˜: Taalas serves Llama 3.1 8B at 17,000 tokens/second&lt;/p&gt;
&lt;hr/&gt;
&lt;h3 style="margin:24px 0 12px;"&gt;Taalas serves Llama 3.1 8B at 17,000 tokens/second&lt;/h3&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;20th February 2026&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;2026å¹´2æœˆ20æ—¥&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;&lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;Taalas&lt;/strong&gt; serves &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;Llama 3.1 8B&lt;/strong&gt; at 17,000 &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;tokens/second&lt;/strong&gt; (via) This new Canadian &lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;hardware startup&lt;/strong&gt; just announced their first product - a custom hardware implementation of the Llama 3.1 8B model (fromJuly 2024) that can run at a staggering 17,000 tokens/second.&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;&lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;Taalas&lt;/strong&gt;ä»¥æ¯ç§’17,000ä¸ª&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;tokenï¼ˆè¯å…ƒï¼‰&lt;/strong&gt;çš„é€Ÿåº¦è¿è¡Œ&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;Llama 3.1 8B&lt;/strong&gt;æ¨¡å‹ï¼ˆviaï¼‰è¿™å®¶åŠ æ‹¿å¤§&lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;ç¡¬ä»¶åˆåˆ›å…¬å¸&lt;/strong&gt;åˆšåˆšå‘å¸ƒäº†ä»–ä»¬çš„é¦–æ¬¾äº§å“â€”â€”Llama 3.1 8Bæ¨¡å‹ï¼ˆå‘å¸ƒäº2024å¹´7æœˆï¼‰çš„å®šåˆ¶ç¡¬ä»¶å®ç°æ–¹æ¡ˆï¼Œè¿è¡Œé€Ÿåº¦é«˜è¾¾æƒŠäººçš„æ¯ç§’17,000ä¸ªtokenã€‚&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;I was going to include a video of their demo but it's so fast it would look more like a screenshot. You can try it out at &lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;chatjimmy.ai&lt;/strong&gt;.&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;æˆ‘æœ¬æ‰“ç®—åµŒå…¥ä»–ä»¬æ¼”ç¤ºçš„è§†é¢‘ï¼Œä½†é€Ÿåº¦å®åœ¨å¤ªå¿«ï¼Œçœ‹èµ·æ¥æ›´åƒæ˜¯ä¸€å¼ é™æ€æˆªå›¾ã€‚ä½ å¯ä»¥åœ¨&lt;strong style="color:#2471a3;background:#eaf4fd;padding:1px 4px;border-radius:3px;"&gt;chatjimmy.ai&lt;/strong&gt;ä¸Šäº²è‡ªä½“éªŒã€‚&lt;/p&gt;

&lt;div style="color:#9a9ea6;font-size:14px;line-height:1.7;margin:20px 0 6px;"&gt;They describe their &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;Silicon Llama&lt;/strong&gt; as "aggressively &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;quantized&lt;/strong&gt;, combining &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;3-bit&lt;/strong&gt; and &lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;6-bit&lt;/strong&gt; parameters." Their next generation will use 4-bit - presumably they have quite a long lead time for baking out new models!&lt;/div&gt;
&lt;p style="color:#2c2c2e;margin:4px 0 24px;line-height:1.8;font-size:15px;"&gt;ä»–ä»¬å°†è¿™æ¬¾&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;Silicon Llama&lt;/strong&gt;æè¿°ä¸º"é‡‡ç”¨æ¿€è¿›çš„&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;é‡åŒ–ï¼ˆquantizedï¼‰&lt;/strong&gt;æŠ€æœ¯ï¼Œç»“åˆäº†&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;3-bit&lt;/strong&gt;å’Œ&lt;strong style="color:#c0392b;background:#fdf2f2;padding:1px 4px;border-radius:3px;"&gt;6-bit&lt;/strong&gt;å‚æ•°"ã€‚ä¸‹ä¸€ä»£äº§å“å°†ä½¿ç”¨4-bitç²¾åº¦â€”â€” presumably ä»–ä»¬åœ¨æµç‰‡ï¼ˆbaking outï¼‰æ–°æ¨¡å‹æ–¹é¢æœ‰ç€ç›¸å½“é•¿çš„äº¤ä»˜å‘¨æœŸï¼&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;ğŸ”— &lt;a href="https://simonwillison.net/2026/Feb/20/taalas/#atom-everything"&gt;é˜…è¯»åŸæ–‡&lt;/a&gt;&lt;/p&gt;</description>
      <guid isPermaLink="false">https://simonwillison.net/2026/Feb/20/taalas/#atom-everything</guid>
      <pubDate>Fri, 20 Feb 2026 22:10:04 +0000</pubDate>
    </item>
  </channel>
</rss>
